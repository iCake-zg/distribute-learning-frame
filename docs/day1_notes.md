# DeepSpeed Day1 学习笔记

## DeepSpeed是什么
- 微软开源的深度学习优化库
- 专门解决大模型训练的内存和计算问题
- 支持数万亿参数模型的训练

## 核心解决的问题
1. **内存问题**: 大模型无法放入单个GPU
2. **计算效率**: 分布式训练的通信开销
3. **易用性**: 简化分布式训练配置

## 主要功能
- Zero优化: 内存优化技术
- 混合精度训练: FP16/BF16支持
- 模型并行: 支持多种并行策略
- 梯度压缩: 减少通信开销

## 与PyTorch的关系
- 基于PyTorch构建
- 无缝集成现有PyTorch代码
- 只需要少量代码修改

# 分布式训练基本概念

## 1. 数据并行 (Data Parallel)
- 每个GPU有完整模型副本
- 不同GPU处理不同的数据批次
- 梯度需要在GPU间同步

## 2. 模型并行 (Model Parallel)  
- 模型被分割到不同GPU上
- 每个GPU只存储模型的一部分
- 适用于单GPU无法存储的大模型

## 3. 流水线并行 (Pipeline Parallel)
- 模型按层分割到不同GPU
- 形成流水线处理机制
- 减少GPU空闲时间

## 4. 关键术语
- **Rank**: 进程编号
- **World Size**: 总进程数
- **Local Rank**: 节点内GPU编号
- **All-Reduce**: 梯度聚合操作